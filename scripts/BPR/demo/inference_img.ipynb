{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=8\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=8"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\echen\\miniconda3\\envs\\jtml\\lib\\site-packages\\mmcv\\__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from inference_img import _build_model, _build_dataloader, split, merge"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: ../ckpts/hrnet18s_128-24055c80.pth\n"
     ]
    }
   ],
   "source": [
    "cfg = \"../configs/bpr/hrnet18s_128.py\"\n",
    "ckpt = \"../ckpts/hrnet18s_128-24055c80.pth\"\n",
    "max_ins = 32         # set to lower value to save GPU memory\n",
    "model = _build_model(cfg, ckpt)\n",
    "\n",
    "def _inference_one(img, sub_maskdts, sub_dt_paths):\n",
    "    dets, patches = split(img, sub_maskdts)\n",
    "    masks = model(patches)[:,1,:,:]                 # N, 128, 128\n",
    "    refineds = merge(sub_maskdts, dets, masks)\n",
    "    out = []\n",
    "    for i, dt_path in enumerate(sub_dt_paths):\n",
    "        out.append(refineds[i].cpu().numpy().astype(np.uint8) * 255)\n",
    "    return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "torch.cat(): expected a non-empty list of Tensors",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 14\u001B[0m\n\u001B[0;32m     12\u001B[0m sub_dt_paths \u001B[38;5;241m=\u001B[39m dt_paths[p:q]\n\u001B[0;32m     13\u001B[0m p \u001B[38;5;241m=\u001B[39m q\n\u001B[1;32m---> 14\u001B[0m refine_mask \u001B[38;5;241m=\u001B[39m \u001B[43m_inference_one\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msub_maskdts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msub_dt_paths\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[3], line 7\u001B[0m, in \u001B[0;36m_inference_one\u001B[1;34m(img, sub_maskdts, sub_dt_paths)\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_inference_one\u001B[39m(img, sub_maskdts, sub_dt_paths):\n\u001B[1;32m----> 7\u001B[0m     dets, patches \u001B[38;5;241m=\u001B[39m \u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msub_maskdts\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m     masks \u001B[38;5;241m=\u001B[39m model(patches)[:,\u001B[38;5;241m1\u001B[39m,:,:]                 \u001B[38;5;66;03m# N, 128, 128\u001B[39;00m\n\u001B[0;32m      9\u001B[0m     refineds \u001B[38;5;241m=\u001B[39m merge(sub_maskdts, dets, masks)\n",
      "File \u001B[1;32m~\\PycharmProjects\\Bone-Meal\\scripts\\BPR\\demo\\inference_img.py:159\u001B[0m, in \u001B[0;36msplit\u001B[1;34m(img, maskdts, boundary_width, iou_thresh, patch_size, out_size)\u001B[0m\n\u001B[0;32m    156\u001B[0m     dets \u001B[38;5;241m=\u001B[39m get_dets(fbmasks[i], patch_size, iou_thresh\u001B[38;5;241m=\u001B[39miou_thresh)[:,:\u001B[38;5;241m4\u001B[39m]\n\u001B[0;32m    157\u001B[0m     detss\u001B[38;5;241m.\u001B[39mappend(dets)\n\u001B[1;32m--> 159\u001B[0m all_dets \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdetss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    160\u001B[0m img \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mfloat()\u001B[38;5;241m.\u001B[39mcontiguous()   \u001B[38;5;66;03m# 1,3,H,W\u001B[39;00m\n\u001B[0;32m    161\u001B[0m img_patches \u001B[38;5;241m=\u001B[39m roi_align(img, _to_rois(all_dets), patch_size)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: torch.cat(): expected a non-empty list of Tensors"
     ]
    }
   ],
   "source": [
    "img_paths = ['jankin.png']\n",
    "mask_paths = [['jankout.png'], ]\n",
    "\n",
    "dataloader = _build_dataloader(img_paths, mask_paths, device='cuda:0')\n",
    "for dc in dataloader:\n",
    "    dt_paths, img, maskdts = dc.data[0][0]\n",
    "    img = img.cuda()\n",
    "    maskdts = maskdts.cuda()\n",
    "    p = 0\n",
    "    for sub_maskdts in maskdts.split(max_ins):\n",
    "        q = p + sub_maskdts.size(0)\n",
    "        sub_dt_paths = dt_paths[p:q]\n",
    "        p = q\n",
    "        refine_mask = _inference_one(img, sub_maskdts, sub_dt_paths)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x1d45c395ee0>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "img = cv2.imread(img_paths[0])[:,:,::-1]\n",
    "coarse_mask = cv2.imread(mask_paths[0][0], 0)\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(20, 15))\n",
    "axs[0].imshow(img)\n",
    "axs[1].imshow(img)\n",
    "axs[1].imshow(coarse_mask, alpha=0.5, cmap=\"Reds\")\n",
    "axs[2].imshow(img)\n",
    "# axs[2].imshow(refine_mask[0], alpha=0.5, cmap=\"Reds\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmseg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d0a01506e7e524745347ccc960965f7512836b8ec8f304ce36f0c02aa867b5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}