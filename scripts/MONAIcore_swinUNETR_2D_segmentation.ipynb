{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **MONAI 2D segmentation with swinUNETR**"
      ],
      "metadata": {
        "id": "uafkrRvArPEQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "McjukF_EsJ3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run this cell once, then restart the runtime. Do not run again.\n",
        "!pip install monai-weekly[nibabel]\n",
        "!pip install einops\n",
        "!pip install ITK\n",
        "!pip install pytorch-ignite\n",
        "!pip install transformers\n",
        "!pip install mlflow\n",
        "!pip install pynrrd version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SNlhTw6o8nI",
        "outputId": "b0da7004-b9b6-41c8-afe1-fce969f52305",
        "cellView": "form"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting monai-weekly[nibabel]\n",
            "  Downloading monai_weekly-1.2.dev2306-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.8 in /usr/local/lib/python3.8/dist-packages (from monai-weekly[nibabel]) (1.13.1+cu116)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from monai-weekly[nibabel]) (1.21.6)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.8/dist-packages (from monai-weekly[nibabel]) (3.0.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.8->monai-weekly[nibabel]) (4.4.0)\n",
            "Installing collected packages: monai-weekly\n",
            "Successfully installed monai-weekly-1.2.dev2306\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 KB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ITK\n",
            "  Downloading itk-5.3.0-cp38-cp38-manylinux_2_28_x86_64.whl (8.3 kB)\n",
            "Collecting itk-registration==5.3.0\n",
            "  Downloading itk_registration-5.3.0-cp38-cp38-manylinux_2_28_x86_64.whl (26.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.6/26.6 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting itk-segmentation==5.3.0\n",
            "  Downloading itk_segmentation-5.3.0-cp38-cp38-manylinux_2_28_x86_64.whl (16.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting itk-filtering==5.3.0\n",
            "  Downloading itk_filtering-5.3.0-cp38-cp38-manylinux_2_28_x86_64.whl (73.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting itk-core==5.3.0\n",
            "  Downloading itk_core-5.3.0-cp38-cp38-manylinux_2_28_x86_64.whl (81.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.2/81.2 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting itk-numerics==5.3.0\n",
            "  Downloading itk_numerics-5.3.0-cp38-cp38-manylinux_2_28_x86_64.whl (58.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from ITK) (1.21.6)\n",
            "Collecting itk-io==5.3.0\n",
            "  Downloading itk_io-5.3.0-cp38-cp38-manylinux_2_28_x86_64.whl (25.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.6/25.6 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: itk-core, itk-numerics, itk-io, itk-filtering, itk-segmentation, itk-registration, ITK\n",
            "Successfully installed ITK-5.3.0 itk-core-5.3.0 itk-filtering-5.3.0 itk-io-5.3.0 itk-numerics-5.3.0 itk-registration-5.3.0 itk-segmentation-5.3.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.4.10-py3-none-any.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.1/264.1 KB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from pytorch-ignite) (23.0)\n",
            "Requirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.8/dist-packages (from pytorch-ignite) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch<2,>=1.3->pytorch-ignite) (4.4.0)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.10\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m107.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mlflow\n",
            "  Downloading mlflow-2.1.1-py3-none-any.whl (16.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker<7,>=4.0.0\n",
            "  Downloading docker-6.0.1-py3-none-any.whl (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.5/147.5 KB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib<4 in /usr/local/lib/python3.8/dist-packages (from mlflow) (3.2.2)\n",
            "Requirement already satisfied: Flask<3 in /usr/local/lib/python3.8/dist-packages (from mlflow) (1.1.4)\n",
            "Requirement already satisfied: pandas<2 in /usr/local/lib/python3.8/dist-packages (from mlflow) (1.3.5)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.8/dist-packages (from mlflow) (2.11.3)\n",
            "Collecting querystring-parser<2\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: pytz<2023 in /usr/local/lib/python3.8/dist-packages (from mlflow) (2022.7.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.8/dist-packages (from mlflow) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.8/dist-packages (from mlflow) (1.0.2)\n",
            "Collecting shap<1,>=0.40\n",
            "  Downloading shap-0.41.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (575 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m575.9/575.9 KB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting databricks-cli<1,>=0.8.7\n",
            "  Downloading databricks-cli-0.17.4.tar.gz (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.3/82.3 KB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gitpython<4,>=2.1.0\n",
            "  Downloading GitPython-3.1.30-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.0/184.0 KB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic<2\n",
            "  Downloading alembic-1.9.2-py3-none-any.whl (210 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.6/210.6 KB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.8/dist-packages (from mlflow) (6.0)\n",
            "Collecting gunicorn<21\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 KB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.8/dist-packages (from mlflow) (7.1.2)\n",
            "Requirement already satisfied: cloudpickle<3 in /usr/local/lib/python3.8/dist-packages (from mlflow) (2.2.1)\n",
            "Requirement already satisfied: entrypoints<1 in /usr/local/lib/python3.8/dist-packages (from mlflow) (0.4)\n",
            "Requirement already satisfied: pyarrow<11,>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from mlflow) (9.0.0)\n",
            "Requirement already satisfied: sqlalchemy<2,>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from mlflow) (1.4.46)\n",
            "Collecting packaging<23\n",
            "  Downloading packaging-22.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.8/dist-packages (from mlflow) (3.4.1)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from mlflow) (0.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.8/dist-packages (from mlflow) (2.25.1)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.8/dist-packages (from mlflow) (1.21.6)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from mlflow) (3.19.6)\n",
            "Collecting importlib-metadata!=4.7.0,<6,>=3.7.0\n",
            "  Downloading importlib_metadata-5.2.0-py3-none-any.whl (21 kB)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from alembic<2->mlflow) (5.10.2)\n",
            "Collecting pyjwt>=1.7.0\n",
            "  Downloading PyJWT-2.6.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (3.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.8/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (0.8.10)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.15.0)\n",
            "Collecting urllib3>=1.26.0\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests<3,>=2.17.3\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.5.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.8/dist-packages (from Flask<3->mlflow) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.8/dist-packages (from Flask<3->mlflow) (1.1.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.8/dist-packages (from gunicorn<21->mlflow) (57.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata!=4.7.0,<6,>=3.7.0->mlflow) (3.12.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2<4,>=2.11->mlflow) (2.0.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4->mlflow) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4->mlflow) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4->mlflow) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.17.3->mlflow) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.17.3->mlflow) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.17.3->mlflow) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn<2->mlflow) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn<2->mlflow) (3.1.0)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.8/dist-packages (from shap<1,>=0.40->mlflow) (4.64.1)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.8/dist-packages (from shap<1,>=0.40->mlflow) (0.56.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy<2,>=1.4.0->mlflow) (2.0.2)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba->shap<1,>=0.40->mlflow) (0.39.1)\n",
            "Building wheels for collected packages: databricks-cli\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.17.4-py3-none-any.whl size=142894 sha256=bbe5312c099fb91bd4b8dac4771b7ec65f9b306ad7fe7bf38f04372328c31958\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/7c/6e/4bf2c1748c7ecf994ca951591de81674ed6bf633e1e337d873\n",
            "Successfully built databricks-cli\n",
            "Installing collected packages: websocket-client, urllib3, smmap, slicer, querystring-parser, pyjwt, packaging, Mako, importlib-metadata, gunicorn, requests, gitdb, alembic, shap, gitpython, docker, databricks-cli, mlflow\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 23.0\n",
            "    Uninstalling packaging-23.0:\n",
            "      Successfully uninstalled packaging-23.0\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 6.0.0\n",
            "    Uninstalling importlib-metadata-6.0.0:\n",
            "      Successfully uninstalled importlib-metadata-6.0.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.25.1\n",
            "    Uninstalling requests-2.25.1:\n",
            "      Successfully uninstalled requests-2.25.1\n",
            "Successfully installed Mako-1.2.4 alembic-1.9.2 databricks-cli-0.17.4 docker-6.0.1 gitdb-4.0.10 gitpython-3.1.30 gunicorn-20.1.0 importlib-metadata-5.2.0 mlflow-2.1.1 packaging-22.0 pyjwt-2.6.0 querystring-parser-1.2.4 requests-2.28.2 shap-0.41.0 slicer-0.0.7 smmap-5.0.0 urllib3-1.26.14 websocket-client-1.5.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pynrrd\n",
            "  Downloading pynrrd-1.0.0-py2.py3-none-any.whl (19 kB)\n",
            "Collecting version\n",
            "  Downloading version-0.1.1.tar.gz (2.0 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright (c) MONAI Consortium\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "from monai.networks.nets import SwinUNETR\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "import tempfile\n",
        "from glob import glob\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import monai\n",
        "from monai.data import ArrayDataset, create_test_image_2d, decollate_batch, DataLoader\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.metrics import DiceMetric\n",
        "from monai.transforms import (\n",
        "    Activations,\n",
        "    AsDiscrete,\n",
        "    Compose,\n",
        "    LoadImage,\n",
        "    RandRotate90,\n",
        "    RandSpatialCrop,\n",
        "    ScaleIntensity,\n",
        ")\n",
        "from monai.visualize import plot_2d_or_3d_image\n",
        "\n",
        "\n",
        "def main(tempdir):\n",
        "    monai.config.print_config()\n",
        "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "\n",
        "    # create a temporary directory and 40 random image, mask pairs\n",
        "    print(f\"generating synthetic data to {tempdir} (this may take a while)\")\n",
        "    for i in range(40):\n",
        "        im, seg = create_test_image_2d(128, 128, num_seg_classes=1)\n",
        "        Image.fromarray((im * 255).astype(\"uint8\")).save(os.path.join(tempdir, f\"img{i:d}.png\"))\n",
        "        Image.fromarray((seg * 255).astype(\"uint8\")).save(os.path.join(tempdir, f\"seg{i:d}.png\"))\n",
        "\n",
        "    images = sorted(glob(os.path.join(tempdir, \"img*.png\")))\n",
        "    segs = sorted(glob(os.path.join(tempdir, \"seg*.png\")))\n",
        "\n",
        "    # define transforms for image and segmentation\n",
        "    train_imtrans = Compose(\n",
        "        [\n",
        "            LoadImage(image_only=True, ensure_channel_first=True),\n",
        "            ScaleIntensity(),\n",
        "            RandSpatialCrop((96, 96), random_size=False),\n",
        "            RandRotate90(prob=0.5, spatial_axes=(0, 1)),\n",
        "        ]\n",
        "    )\n",
        "    train_segtrans = Compose(\n",
        "        [\n",
        "            LoadImage(image_only=True, ensure_channel_first=True),\n",
        "            ScaleIntensity(),\n",
        "            RandSpatialCrop((96, 96), random_size=False),\n",
        "            RandRotate90(prob=0.5, spatial_axes=(0, 1)),\n",
        "        ]\n",
        "    )\n",
        "    val_imtrans = Compose([LoadImage(image_only=True, ensure_channel_first=True), ScaleIntensity()])\n",
        "    val_segtrans = Compose([LoadImage(image_only=True, ensure_channel_first=True), ScaleIntensity()])\n",
        "\n",
        "    # define array dataset, data loader\n",
        "    check_ds = ArrayDataset(images, train_imtrans, segs, train_segtrans)\n",
        "    check_loader = DataLoader(check_ds, batch_size=10, num_workers=2, pin_memory=torch.cuda.is_available())\n",
        "    im, seg = monai.utils.misc.first(check_loader)\n",
        "    print(im.shape, seg.shape)\n",
        "\n",
        "    # create a training data loader\n",
        "    train_ds = ArrayDataset(images[:20], train_imtrans, segs[:20], train_segtrans)\n",
        "    train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=8, pin_memory=torch.cuda.is_available())\n",
        "    # create a validation data loader\n",
        "    val_ds = ArrayDataset(images[-20:], val_imtrans, segs[-20:], val_segtrans)\n",
        "    val_loader = DataLoader(val_ds, batch_size=1, num_workers=4, pin_memory=torch.cuda.is_available())\n",
        "    dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
        "    post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
        "    # create UNet, DiceLoss and Adam optimizer\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    model = SwinUNETR(img_size=(128,128), in_channels=1, out_channels=1,  spatial_dims=2).to(device)\n",
        "    loss_function = monai.losses.DiceLoss(sigmoid=True)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
        "\n",
        "    # start a typical PyTorch training\n",
        "    val_interval = 2\n",
        "    best_metric = -1\n",
        "    best_metric_epoch = -1\n",
        "    epoch_loss_values = list()\n",
        "    metric_values = list()\n",
        "    writer = SummaryWriter()\n",
        "    for epoch in range(10):\n",
        "        print(\"-\" * 10)\n",
        "        print(f\"epoch {epoch + 1}/{10}\")\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        step = 0\n",
        "        for batch_data in train_loader:\n",
        "            step += 1\n",
        "            inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_function(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_len = len(train_ds) // train_loader.batch_size\n",
        "            print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
        "            writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
        "        epoch_loss /= step\n",
        "        epoch_loss_values.append(epoch_loss)\n",
        "        print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
        "\n",
        "        if (epoch + 1) % val_interval == 0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                val_images = None\n",
        "                val_labels = None\n",
        "                val_outputs = None\n",
        "                for val_data in val_loader:\n",
        "                    val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
        "                    roi_size = (96, 96)\n",
        "                    sw_batch_size = 4\n",
        "                    val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, model)\n",
        "                    val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n",
        "                    # compute metric for current iteration\n",
        "                    dice_metric(y_pred=val_outputs, y=val_labels)\n",
        "                # aggregate the final mean dice result\n",
        "                metric = dice_metric.aggregate().item()\n",
        "                # reset the status for next validation round\n",
        "                dice_metric.reset()\n",
        "                metric_values.append(metric)\n",
        "                if metric > best_metric:\n",
        "                    best_metric = metric\n",
        "                    best_metric_epoch = epoch + 1\n",
        "                    torch.save(model.state_dict(), \"best_metric_model_segmentation2d_array.pth\")\n",
        "                    print(\"saved new best metric model\")\n",
        "                print(\n",
        "                    \"current epoch: {} current mean dice: {:.4f} best mean dice: {:.4f} at epoch {}\".format(\n",
        "                        epoch + 1, metric, best_metric, best_metric_epoch\n",
        "                    )\n",
        "                )\n",
        "                writer.add_scalar(\"val_mean_dice\", metric, epoch + 1)\n",
        "                # plot the last model output as GIF image in TensorBoard with the corresponding image and label\n",
        "                plot_2d_or_3d_image(val_images, epoch + 1, writer, index=0, tag=\"image\")\n",
        "                plot_2d_or_3d_image(val_labels, epoch + 1, writer, index=0, tag=\"label\")\n",
        "                plot_2d_or_3d_image(val_outputs, epoch + 1, writer, index=0, tag=\"output\")\n",
        "\n",
        "    print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
        "    writer.close()\n",
        "\n",
        "\n",
        "#if __name__ == \"__main__\":\n",
        "    #with tempfile.TemporaryDirectory() as tempdir:\n",
        "     #   main(tempdir)"
      ],
      "metadata": {
        "id": "tOn27Z2YXveo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tempfile.TemporaryDirectory() as tempdir:\n",
        "     main(tempdir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qaJpkTmY1ri",
        "outputId": "04a86bf9-cb10-4d26-e86e-7dcccedcc942"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MONAI version: 1.2.dev2306\n",
            "Numpy version: 1.21.6\n",
            "Pytorch version: 1.13.1+cu116\n",
            "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
            "MONAI rev id: 4fd4fb01b9f5e329f1efb55b52bdcd0d6f95497f\n",
            "MONAI __file__: /usr/local/lib/python3.8/dist-packages/monai/__init__.py\n",
            "\n",
            "Optional dependencies:\n",
            "Pytorch Ignite version: 0.4.10\n",
            "ITK version: 5.3.0\n",
            "Nibabel version: 3.0.2\n",
            "scikit-image version: 0.18.3\n",
            "Pillow version: 7.1.2\n",
            "Tensorboard version: 2.9.1\n",
            "gdown version: 4.4.0\n",
            "TorchVision version: 0.14.1+cu116\n",
            "tqdm version: 4.64.1\n",
            "lmdb version: 0.99\n",
            "psutil version: 5.4.8\n",
            "pandas version: 1.3.5\n",
            "einops version: 0.6.0\n",
            "transformers version: 4.26.0\n",
            "mlflow version: 2.1.1\n",
            "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "\n",
            "For details about installing the optional dependencies, please visit:\n",
            "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
            "\n",
            "generating synthetic data to /tmp/tmpw4lb6fy0 (this may take a while)\n",
            "torch.Size([10, 1, 96, 96]) torch.Size([10, 1, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "epoch 1/10\n",
            "1/5, train_loss: 0.4081\n",
            "2/5, train_loss: 0.3108\n",
            "3/5, train_loss: 0.2610\n",
            "4/5, train_loss: 0.2261\n",
            "5/5, train_loss: 0.1992\n",
            "epoch 1 average loss: 0.2810\n",
            "----------\n",
            "epoch 2/10\n",
            "1/5, train_loss: 0.1919\n",
            "2/5, train_loss: 0.1842\n",
            "3/5, train_loss: 0.1511\n",
            "4/5, train_loss: 0.1486\n",
            "5/5, train_loss: 0.1350\n",
            "epoch 2 average loss: 0.1622\n",
            "saved new best metric model\n",
            "current epoch: 2 current mean dice: 0.9940 best mean dice: 0.9940 at epoch 2\n",
            "----------\n",
            "epoch 3/10\n",
            "1/5, train_loss: 0.1389\n",
            "2/5, train_loss: 0.1419\n",
            "3/5, train_loss: 0.1267\n",
            "4/5, train_loss: 0.1365\n",
            "5/5, train_loss: 0.1282\n",
            "epoch 3 average loss: 0.1344\n",
            "----------\n",
            "epoch 4/10\n",
            "1/5, train_loss: 0.1194\n",
            "2/5, train_loss: 0.1082\n",
            "3/5, train_loss: 0.1264\n",
            "4/5, train_loss: 0.1125\n",
            "5/5, train_loss: 0.1169\n",
            "epoch 4 average loss: 0.1167\n",
            "saved new best metric model\n",
            "current epoch: 4 current mean dice: 0.9975 best mean dice: 0.9975 at epoch 4\n",
            "----------\n",
            "epoch 5/10\n",
            "1/5, train_loss: 0.1278\n",
            "2/5, train_loss: 0.0978\n",
            "3/5, train_loss: 0.1099\n",
            "4/5, train_loss: 0.1248\n",
            "5/5, train_loss: 0.0936\n",
            "epoch 5 average loss: 0.1108\n",
            "----------\n",
            "epoch 6/10\n",
            "1/5, train_loss: 0.0987\n",
            "2/5, train_loss: 0.1051\n",
            "3/5, train_loss: 0.0882\n",
            "4/5, train_loss: 0.1016\n",
            "5/5, train_loss: 0.0823\n",
            "epoch 6 average loss: 0.0952\n",
            "saved new best metric model\n",
            "current epoch: 6 current mean dice: 0.9987 best mean dice: 0.9987 at epoch 6\n",
            "----------\n",
            "epoch 7/10\n",
            "1/5, train_loss: 0.0916\n",
            "2/5, train_loss: 0.0874\n",
            "3/5, train_loss: 0.1061\n",
            "4/5, train_loss: 0.0779\n",
            "5/5, train_loss: 0.0778\n",
            "epoch 7 average loss: 0.0882\n",
            "----------\n",
            "epoch 8/10\n",
            "1/5, train_loss: 0.0748\n",
            "2/5, train_loss: 0.0753\n",
            "3/5, train_loss: 0.0865\n",
            "4/5, train_loss: 0.0849\n",
            "5/5, train_loss: 0.0716\n",
            "epoch 8 average loss: 0.0786\n",
            "saved new best metric model\n",
            "current epoch: 8 current mean dice: 0.9992 best mean dice: 0.9992 at epoch 8\n",
            "----------\n",
            "epoch 9/10\n",
            "1/5, train_loss: 0.0662\n",
            "2/5, train_loss: 0.0838\n",
            "3/5, train_loss: 0.0784\n",
            "4/5, train_loss: 0.0911\n",
            "5/5, train_loss: 0.0655\n",
            "epoch 9 average loss: 0.0770\n",
            "----------\n",
            "epoch 10/10\n",
            "1/5, train_loss: 0.0689\n",
            "2/5, train_loss: 0.0622\n",
            "3/5, train_loss: 0.0662\n",
            "4/5, train_loss: 0.0795\n",
            "5/5, train_loss: 0.0590\n",
            "epoch 10 average loss: 0.0672\n",
            "saved new best metric model\n",
            "current epoch: 10 current mean dice: 0.9995 best mean dice: 0.9995 at epoch 10\n",
            "train completed, best_metric: 0.9995 at epoch: 10\n"
          ]
        }
      ]
    }
  ]
}